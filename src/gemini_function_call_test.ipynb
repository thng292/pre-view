{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "JD = \"\"\"\n",
    "Mô tả công việc\n",
    "LG CNS is looking for full stack developers for cloud domain project\n",
    "\n",
    "Develop software/web applicant\n",
    "Business Analyst\n",
    "Cooperate between HQ and VNB\n",
    "\n",
    "Yêu cầu ứng viên\n",
    "[Required]\n",
    "\n",
    "Bachelor's degree of Information Technology or higher\n",
    "Have working experiment and excellent knowledge at software developing using Java, Spring boot\n",
    "Have working experiment and excellent knowledge at software developing using React, HTML, JavaScript\n",
    "Good knowledge about AI (Azure OpenAI and GenAI)\n",
    "Good knowledge about public cloud (Azure, AWS,)\n",
    "Database: MariaDB (or MySQL).\n",
    "[Preferred]\n",
    "\n",
    "Having experiment with Python and Google cloud\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_SYSTEM_INSTRUCTION = f\"\"\"You are an interviewer for job with description:\n",
    "{JD}\n",
    "\n",
    "You are interviewing interviewee. You will ccommunicate directly with interviewee.\n",
    "You will use function call get_qestion to get interview question to ask interviewee then receive answer from interviewee, \n",
    "you analyitc the answer then use function call result to send your evaluate, score of the answer (a number from 0 to 10) and your suggest following action include: change next topic, following current topic, code interview, stop interview, then get next step you will do from return of function, you must do following instruction.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION_GENERATE_INSTRUCTION = f\"\"\"You are an interviewer for job with description:\n",
    "{JD}\n",
    "\n",
    "Generate suitable question base on job description and chat history.\n",
    "output only 1 question. output question content only without any explain.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_QUESTION_GENERATE_INSTRUCTION = f\"\"\"You are an interviewer for job with description:\n",
    "{JD}\n",
    "\n",
    "Generate suitable code question base on job description and chat history.\n",
    "must more detail as possible, with detail description and with at least 5 testcase (input/output sample pair), \n",
    "without solving question, in hard medium level\n",
    "output only 1 question. output question content only without any explain.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATE_INSTRUCTION = f\"\"\"You are an interviewer for job with description:\n",
    "{JD}\n",
    "\n",
    "I will give you chat history. \n",
    "Evaluate interview progress base on job description and chat history.\n",
    "Make sure cover all topic of job description.\n",
    "Change to next topic if you evaluate interviewee fully answer question or interviewee wrong answer question.\n",
    "Give choose suitable action following to do: change next topic, following current topic, code interview, stop interview\n",
    "Output progress as a number from 0 to 100 represent progress of interview.\n",
    "Output total score of interviewee as a number from 0 to 100.\n",
    "Output analysis why choose the action\n",
    "Only output action i listed.\n",
    "Only output result json, mustn't output markdown\n",
    "Output json in format: progress: \"\", action: \"\", score: \"\", analysis: \"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dotenv\n",
    "import google.generativeai as genai\n",
    "dotenv.load_dotenv(\".env\")\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_qestion(chatHistory, action):\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\", system_instruction=QUESTION_GENERATE_INSTRUCTION)\n",
    "    response = model.generate_content(f\"Generate {action} question base on job description and chat history: {chatHistory}\")\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_code_qestion(chatHistory):\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\", system_instruction=CODE_QUESTION_GENERATE_INSTRUCTION)\n",
    "    response = model.generate_content(f\"Generate code question base on job description and chat history: {chatHistory}\")\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "from google.generativeai import GenerationConfig\n",
    "\n",
    "Retry = 5\n",
    "\n",
    "class ActionTag(str, Enum):\n",
    "    NextTopic = \"change next topic\"\n",
    "    CurrentTopic = \"following current topic\"\n",
    "    CodeInterview = \"code interview\"\n",
    "    StopInterview = \"stop interview\"\n",
    "\n",
    "class EvaluationExtractedOutput(BaseModel):\n",
    "    analysis: str\n",
    "    action: ActionTag\n",
    "    score: float\n",
    "    progress: float\n",
    "\n",
    "def generate_evaluate(chatHistory: str, qestion: str, answer: str):\n",
    "    for _ in range(Retry):\n",
    "        try:\n",
    "            model = genai.GenerativeModel(\"gemini-1.5-flash\", system_instruction=EVALUATE_INSTRUCTION,\n",
    "                                    generation_config=GenerationConfig(\n",
    "                                                    response_mime_type=\"application/json\"))\n",
    "            response = model.generate_content(f\"Evaluate interview progress base on job description and chat history: {chatHistory}\\n Interviewer: {qestion}\\n Interviewee: {answer}\")\n",
    "            #print(response.text)\n",
    "            return EvaluationExtractedOutput(**json.loads(response.text))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import google.generativeai as genai\n",
    "\n",
    "\n",
    "i = 0\n",
    "chatHistory = \"\"\n",
    "currentQuestion = \"\"\n",
    "currentAnswer = \"\"\n",
    "nextAction = \"\"\n",
    "\n",
    "def result(evaluate: str, score: float, action: str):\n",
    "    print(\"- review:\", evaluate)\n",
    "    score = np.clip(score, 0, 10)\n",
    "    print(\"- score:\", score)\n",
    "    print(\"- action:\", action)\n",
    "    global i\n",
    "    global currentQuestion\n",
    "    global currentAnswer\n",
    "    global chatHistory\n",
    "    global nextAction\n",
    "    nextAction = action\n",
    "    i += 1\n",
    "    #evl = generate_evaluate(chatHistory, currentQuestion, currentAnswer)\n",
    "    #print(evl)\n",
    "    \"\"\"Send evaluate and score about the answer provided by interviewee and get next step command.\n",
    "    Args: \n",
    "        evaluate: your evaluate about the answer provided by interviewee.\n",
    "        score: floating point number from 0 to 10 represent your score for the answer provided by interviewee.\n",
    "        action: suggest following action for interviewer include: change next topic, following current topic, code interview, stop interview.\n",
    "    Returns: \n",
    "        A string that is next step you will do.\n",
    "    \"\"\"\n",
    "    return \"ask interviewee next question, use function call get_qestion to get interview question then receive answer from interviewee, you analyitc the answer then use function call result to send your evaluate, score of the answer (a number from 0 to 10) and your suggest following action for interviewer include: change next topic, following current topic, code interview, stop interview, then get next step you will do from return of function. you must do following instruction.\" if i <= 20 and action.find(\"stop\") == -1 else \"stop interview\"\n",
    "\n",
    "\n",
    "def get_qestion():\n",
    "    global i\n",
    "    global chatHistory\n",
    "    global currentQuestion\n",
    "    global nextAction\n",
    "    if nextAction.find(\"code\") != -1:\n",
    "        currentQuestion = generate_code_qestion(chatHistory) \n",
    "    else:\n",
    "        currentQuestion = generate_qestion(chatHistory, nextAction) \n",
    "    #print(i)\n",
    "    #print(chatHistory)\n",
    "    \"\"\"Get Qestion for interview\n",
    "\n",
    "    Args:\n",
    "        \n",
    "    Returns:\n",
    "        A string that is a qestion you will ask interviewee.\n",
    "    \"\"\"\n",
    "    return currentQuestion\n",
    "\n",
    "import time\n",
    "class ChatSession:\n",
    "    def __init__(self):\n",
    "        self.model = genai.GenerativeModel(model_name='gemini-1.5-flash',\n",
    "                                    system_instruction=CHAT_SYSTEM_INSTRUCTION,\n",
    "                                    tools=[get_qestion, result])\n",
    "        self.chat = self.model.start_chat(enable_automatic_function_calling=True)\n",
    "        self.last_send_time = time.time()\n",
    "\n",
    "    def sendUserMessage(self, data: str):\n",
    "        global currentAnswer\n",
    "        global chatHistory\n",
    "        currentAnswer = data\n",
    "        try:\n",
    "            time.sleep(time.time() - self.last_send_time - 60/15)\n",
    "        except:\n",
    "            pass\n",
    "        response = self.chat.send_message(data)\n",
    "        self.last_send_time = time.time()\n",
    "        chatHistory += \"Interviewee: \" + data + \"\\n\"\n",
    "        chatHistory += \"Interviewer: \" + response.candidates[0].content.parts[0].text + \"\\n\"\n",
    "        return response.candidates[0].content.parts[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, let's start the interview.  The first question is: Describe your experience developing and deploying a complex application using Java Spring Boot, React, and a public cloud platform like Azure or AWS, incorporating AI features such as Azure OpenAI or similar technologies.  Please provide a detailed explanation of your role, the technologies used, and the challenges you faced.\\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatSession = ChatSession()\n",
    "chatSession.sendUserMessage(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- review: The candidate demonstrates limited experience with the required technologies and lacks practical experience in integrating AI, deploying applications to the cloud, and handling complex application development. The response is vague and lacks specifics.  The candidate relies heavily on hypothetical scenarios and doesn\\'t showcase any problem-solving skills or in-depth technical understanding. \n",
      "- score: 3.0\n",
      "- action: following current topic\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My next question is: Describe a situation where you had to integrate AI capabilities (e.g., using Azure OpenAI) into a Spring Boot application, and how you addressed potential challenges related to data security and performance.\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatSession.sendUserMessage(\"\"\"\n",
    "**Answer (as a poor interviewee):**\n",
    "\n",
    "Uh, well, I’ve used **Java Spring Boot** and **React** for a few projects, but I can’t say I have a lot of in-depth experience with them together. I mean, I’ve worked on some backend APIs in Spring Boot, like setting up RESTful services and connecting to databases, but for React, I mostly just followed tutorials and didn’t build too many complex features. \n",
    "\n",
    "As for AI integration, I think I’ve heard about Azure OpenAI, but I’ve never really worked with it directly. I know it’s like, some API that you can use for natural language stuff, right? But I haven’t had to integrate AI into a project myself. I think if I were to do it, I’d probably start by looking at some docs or tutorials on how to call an AI service from a backend like Spring Boot and then figure out how to get the response to React. Maybe I’d send some text data to the API and get some kind of result, but I’m not 100% sure how it all works together in practice.\n",
    "\n",
    "I’ve also never really had to deploy something with AI in it before. I know Azure and AWS can host applications, but I haven’t done that personally. I’m sure there’s a lot of configuration to deal with, but I’d probably figure it out as I go along. So yeah, that’s about the extent of my experience with Spring Boot, React, and AI.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- review: The candidate still lacks practical experience in integrating AI and handling related challenges. The response is hypothetical and lacks concrete examples. While the candidate outlines a general approach, they fail to demonstrate a deep understanding of security best practices, error handling, or performance optimization. The reliance on tutorials suggests a lack of independent problem-solving skills.\n",
      "- score: 4.0\n",
      "- action: code interview\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Okay, let's proceed with a coding exercise.  I'd like you to design and implement a RESTful API using Spring Boot that allows users to upload images and receive AI-generated captions for those images.  The API should utilize Azure OpenAI's image captioning capabilities.  Consider error handling, rate limiting, security, logging, and data storage in MariaDB. I've provided test cases to guide your implementation.  Please outline your design and then we can proceed to code.  Remember to address all the aspects mentioned, including image upload, handling various error conditions, rate limiting to prevent exceeding Azure OpenAI service limits, robust logging, security measures, and data storage in MariaDB.  The response should include the generated caption and relevant metadata.\\n\\n\\n\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatSession.sendUserMessage(\"\"\"Um, I haven’t worked on a project where I used Azure OpenAI or any GenAI tools with Java Spring Boot and React, but if I had to do it, I think I’d start by, like, understanding how the API works. I’d look at the documentation to see how to send requests and what kind of responses I could get.\n",
    "\n",
    "For example, if the application needed to use AI to generate text or answer user questions, I would probably call the API from the backend in Spring Boot. I’d use something like RestTemplate or maybe WebClient to make the request to the AI service, and then I’d pass the response to the React frontend through a REST API.\n",
    "\n",
    "The hard part would probably be dealing with authentication for the AI API, like using an API key or a token. I might struggle with where to securely store the key or how to rotate it if needed. I’d also need to make sure the responses from the AI service were properly handled, especially if the response times were slow or if the service went down.\n",
    "\n",
    "On the frontend, I’d build a simple UI in React where users could input their query or text. Then, I’d call the backend API to process the request. If there were issues, like delays or errors, I think I’d need to add some kind of error handling or loading indicator.\n",
    "\n",
    "I haven’t done this before, so I’d probably rely a lot on tutorials or guides to get it working. It might take me some time to figure everything out, but I think I could make it work eventually.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- review: The candidate's responses throughout the interview have demonstrated a lack of practical experience and problem-solving skills. Their answers have been vague, hypothetical, and lacked concrete examples.  The candidate does not meet the requirements for the position.\n",
      "- score: 2.0\n",
      "- action: stop interview\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the candidate's responses throughout the interview, I recommend stopping the interview.  The candidate has consistently demonstrated a lack of practical experience and problem-solving skills, failing to meet the requirements for the position.\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatSession.sendUserMessage(\"\"\"Uh, I think I’ve worked with people in different countries before, but I don’t remember a specific project. It was kind of tricky because of the time zone differences, and sometimes we had to wait a long time to get responses. I think we used email and maybe Slack or something like that to communicate.\n",
    "\n",
    "One thing I tried to do was send detailed messages so they could understand what I needed, but sometimes I didn’t include enough details, and they’d ask follow-up questions, which delayed things. We also had a few meetings, but it was hard to schedule them because of the time difference. I think I missed one because I got confused about the time zones.\n",
    "\n",
    "If I had to do it again, I’d probably try to plan better and maybe use a tool to keep track of the time zones so I wouldn’t miss meetings. I’d also try to write clearer messages to avoid back-and-forth delays. So yeah, that’s how it went. It wasn’t perfect, but we managed to get things done eventually.\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
